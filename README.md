
# ğŸ“˜ **Pipeline DECIDE (ClassificaÃ§Ã£o de Queries com LLMs)**

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o da primeira parte do trabalho DECIDE, cujo objetivo Ã© classificar queries provenientes do Google Trends segundo o mÃ©todo descrito no artigo de referÃªncia (Supplement Box 2).

O pipeline aplica **trÃªs classificaÃ§Ãµes por query**:

1. **Run 1 â€“ ClassificaÃ§Ã£o LLM (Prompt do Supplement Box 2A)**
2. **Run 2 â€“ ClassificaÃ§Ã£o LLM com batches reorganizados (para replicar o mÃ©todo do artigo)**
3. **ClassificaÃ§Ã£o baseada em regras sintÃ¡ticas (Supplement Box 2B)**

As duas primeiras utilizam um modelo LLM e a terceira utiliza heurÃ­sticas linguÃ­sticas.

---

## ğŸ§© **1. Ambiente â€“ InstalaÃ§Ã£o**

Recomenda-se criar um ambiente dedicado:

```bash
mamba create -n decide_env python=3.10
mamba activate decide_env
```

Instalar dependÃªncias:

```bash
pip install groq pandas python-dotenv openpyxl
```

---

## ğŸ”‘ **2. API Key**

Criar um ficheiro `.env` na raiz do projeto contendo:

```
GROQ_API_KEY=INSERIR_AQUI_A_CHAVE_DA_GROQ
```

A Groq API foi usada numa fase inicial por ser gratuita e rÃ¡pida. Contudo, devido ao limite diÃ¡rio de 100 000 tokens, pode ser necessÃ¡rio migrar futuramente para a API da OpenAI.

---

## ğŸ“‚ **3. Estrutura do Projeto**

```
ğŸ“ DECIDE/
 â”œâ”€â”€ pipeline_groupA.py           # pipeline completo em Python
 â”œâ”€â”€ pipeline_groupA_test.ipynb   # notebook com passos testÃ¡veis
 â”œâ”€â”€ queries_middle_east.xlsx     # dataset original
 â”œâ”€â”€ pipeline_decide.log          # ficheiro de logs (gerado automaticamente)
 â”œâ”€â”€ .env                         # chave da API (nÃ£o partilhar)
 â””â”€â”€ README.md                    # este documento
```

---

## â–¶ï¸ **4. Como correr o pipeline**

### **OpÃ§Ã£o A â€” Script Python**

```bash
python pipeline_decide.py
```

### **OpÃ§Ã£o B â€” Notebook**

Abrir:

```
pipeline_decide.ipynb
```

e executar cÃ©lula a cÃ©lula para testar e ajustar parÃ¢metros.

---

## ğŸ” **5. Passos realizados pelo pipeline**

### âœ” **1) Ler o ficheiro `.xlsx`**

* remoÃ§Ã£o de linhas vazias
* normalizaÃ§Ã£o Unicode e limpeza do texto

---

### âœ” **2) DeduplicaÃ§Ã£o**

* criaÃ§Ã£o de um `UniqueID` por query Ãºnica
* evita classificaÃ§Ãµes repetidas
* garante merges seguros

---

### âœ” **3) Run 1 â€” ClassificaÃ§Ã£o LLM**

* modelo usado: **LLaMA 3.3 70B (Groq API)**
* batches de 50 queries
* prompt igual ao do Supplement Box 2A (extendido)

---

### âœ” **4) Run 2 â€” ClassificaÃ§Ã£o LLM com batches diferentes**

Para replicar fielmente o mÃ©todo do artigo:

> â€œDifferent query combinations were used in each round.â€

* queries embaralhadas com `.sample(frac=1)`
* batches novos â†’ contexto diferente

---

### âœ” **5) ClassificaÃ§Ã£o por regras sintÃ¡ticas**

Baseada no Supplement Box 2B:

* identificaÃ§Ã£o de palavras interrogativas (EN, ES, PT, FR, AR, FA, TR, UR)
* padrÃµes sintÃ¡ticos
* partÃ­culas interrogativas
* pontuaÃ§Ã£o
* mÃ©todo totalmente determinÃ­stico

Resultado guardado em `rules.xlsx`.

---

### âœ” **6) Merge final**

Merge realizado por `UniqueID`, garantindo:

* consistÃªncia entre runs
* tolerÃ¢ncia a alteraÃ§Ãµes mÃ­nimas do texto
* ausÃªncia de conflitos

O ficheiro final:

```
queries_classificadas_llm.xlsx
```

contÃ©m:

* Query
* ClassificaÃ§Ã£o Run 1
* ClassificaÃ§Ã£o Run 2
* ClassificaÃ§Ã£o por Regras

E mantÃ©m as colunas originais do dataset.

---

## ğŸ“Š **7. LimitaÃ§Ãµes da Groq API**

A Groq Ã©:

* gratuita
* extremamente rÃ¡pida
* compatÃ­vel com modelos fortes (LLaMA 70B)

Mas possui um limite diÃ¡rio de **100 000 tokens**, o que pode impedir o processamento completo do dataset sem pausas.

