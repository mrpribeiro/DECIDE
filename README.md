
# üìò **Pipeline DECIDE (Classifica√ß√£o de Queries com LLMs)**

Este reposit√≥rio cont√©m a implementa√ß√£o da primeira parte do trabalho DECIDE, cujo objetivo √© classificar queries do Google Trends segundo a metodologia apresentada no artigo AIM ‚Äì Artificial Intelligence Supported Development of Health Guidelines (em particular o Supplement Box 2).

O pipeline aplica **tr√™s classifica√ß√µes independentes por query**:

1. **Run 1 ‚Äì Classifica√ß√£o LLM (Prompt do Supplement Box 2A)**
2. **Run 2 ‚Äì Classifica√ß√£o LLM com batches reorganizados (para replicar o m√©todo do artigo)**
3. **Classifica√ß√£o baseada em regras sint√°ticas (Supplement Box 2B expandido)**

As duas primeiras utilizam um modelo LLM e a terceira utiliza heur√≠sticas lingu√≠sticas.

---

## üß© **1. Ambiente ‚Äì Instala√ß√£o**

Recomenda-se criar um ambiente dedicado:

```bash
mamba create -n decide_env python=3.10
mamba activate decide_env
```

Instalar depend√™ncias:

```bash
pip install groq pandas python-dotenv openpyxl perplexityai
```

---

## üîë **2. API Key**

Criar um ficheiro `.env` na raiz do projeto contendo:

```
PERPLEXITY_API_KEY=INSERIR_AQUI_A_CHAVE
```

Nota: Inicialmente testou-se Groq API por ser gratuita, mas devido ao limite di√°rio de tokens, o pipeline foi migrado para Perplexity API, especificamente o modelo sonar, utilizado como LLM de classifica√ß√£o.

---

## üìÇ **3. Estrutura do Projeto**

```
üìÅ DECIDE/
 ‚îú‚îÄ‚îÄ pipeline_groupA.py           # pipeline completo (vers√£o final)
 ‚îú‚îÄ‚îÄ pipeline_groupA_teste.ipynb  # notebook para testes passo a passo
 ‚îú‚îÄ‚îÄ queries_middle_east.xlsx     # dataset original
 ‚îú‚îÄ‚îÄ df_unique.xlsx               # queries √∫nicas com UniqueID
 ‚îú‚îÄ‚îÄ df_run1.xlsx                 # classifica√ß√µes da Run 1
 ‚îú‚îÄ‚îÄ df_run2.xlsx                 # classifica√ß√µes da Run 2
 ‚îú‚îÄ‚îÄ df_rules.xlsx                # classifica√ß√µes por regras
 ‚îú‚îÄ‚îÄ queries_classificadas_COMPLETO.xlsx   # output final
 ‚îú‚îÄ‚îÄ pipeline_run_YYYY-MM-DD.log  # logs gerados automaticamente
 ‚îî‚îÄ‚îÄ README.md                    # este documento

```

---

## ‚ñ∂Ô∏è **4. Como correr o pipeline**

### **Op√ß√£o A ‚Äî Script Python**

```bash
python3 pipeline_decide.py
```

### **Op√ß√£o B ‚Äî Notebook**

Abrir:

```
pipeline_decide.ipynb
```

e executar c√©lula a c√©lula para testar e ajustar par√¢metros.

---

## üîç **5. Passos realizados pelo pipeline**

### ‚úî **1) Ler o ficheiro `.xlsx`**

* remo√ß√£o de linhas vazias
* normaliza√ß√£o Unicode e limpeza do texto

---

### ‚úî **2) Deduplica√ß√£o**

* cria√ß√£o de um `UniqueID` por query √∫nica
* evita classifica√ß√µes repetidas
* garante merges seguros

---

### ‚úî **3) Run 1 ‚Äî Classifica√ß√£o LLM**

* modelo usado: **sonar (Perplexity)**
* batches de 50 queries
* prompt igual ao do Supplement Box 2A (adaptado e extendido)
* output for√ßado a JSON
* parsing robusto para lidar com respostas n√£o formatadas

---

### ‚úî **4) Run 2 ‚Äî Classifica√ß√£o LLM com batches diferentes**

Para replicar fielmente o m√©todo do artigo:

> ‚ÄúDifferent query combinations were used in each round.‚Äù

* queries embaralhadas com `.sample(frac=1)`
* batches novos ‚Üí contexto diferente

---

### ‚úî **5) Classifica√ß√£o por regras sint√°ticas**

Baseada no Supplement Box 2B:

* identifica√ß√£o de palavras interrogativas (EN, ES, PT, FR, DE, NL, RU, AR, FA, TR)
* padr√µes sint√°ticos
* part√≠culas interrogativas
* detec√ß√£o de pedidos impl√≠citos
* m√©todo totalmente determin√≠stico

---

### ‚úî **6) Merge final**

Merge realizado por `UniqueID`, garantindo:

* consist√™ncia entre runs
* toler√¢ncia a altera√ß√µes m√≠nimas do texto
* aus√™ncia de conflitos

O ficheiro final:

```
queries_classificadas_llm.xlsx
```

cont√©m:

* Query
* UniqueID
* Classifica√ß√£o Run 1
* Classifica√ß√£o Run 2
* Classifica√ß√£o por Regras

E mant√©m as colunas originais do dataset.

---

## üìä **7. Limita√ß√µes e Notas**

‚ö†Ô∏è Limite da Perplexity API (PRO)

O modelo sonar funciona bem, mas:
* se o utilizador n√£o tiver plano PRO, h√° limites fortes
* cada batch consome tokens rapidamente
* recomendamos correr apenas uma vez sobre o dataset final

‚ö†Ô∏è JSON pode falhar quando o modelo inclui texto extra

O c√≥digo possui:
* mecanismo de fallback
* logger + exporta√ß√£o de respostas falhadas para failed_batch.txt
* Isto permite depurar problemas sem interromper a execu√ß√£o.

