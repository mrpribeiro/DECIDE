{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd727c1c",
   "metadata": {},
   "source": [
    "# DECIDE – Pipeline LLM para classificação de queries (Groq API)\n",
    "\n",
    "Este notebook replica o ficheiro `pipeline_decide.py` mas em formato interativo,\n",
    "para podermos:\n",
    "- testar cada passo,\n",
    "- inspecionar DataFrames,\n",
    "- alterar parâmetros (modelo, batch size, prompt, etc.).\n",
    "\n",
    "### Ambiente recomendado\n",
    "\n",
    "```bash\n",
    "mamba create -n decide_env python=3.10\n",
    "mamba activate decide_env\n",
    "pip install groq pandas python-dotenv openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 10:07:31 | INFO | ✅ Ambiente carregado e cliente Groq configurado.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# ============================================================\n",
    "# LOGGING CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "log_filename = datetime.now().strftime(\"pipeline_run_%Y-%m-%d_%H-%M-%S.log\")\n",
    "\n",
    "\n",
    "log_handler = RotatingFileHandler(\n",
    "    log_filename,\n",
    "    maxBytes=5_000_000,\n",
    "    backupCount=3,\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "log_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(\"DECIDE_PIPELINE\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(log_handler)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURAR GROQ API\n",
    "# ============================================================\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Variável de ambiente GROQ_API_KEY não definida.\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "BATCH_SIZE = 50   # número de queries por batch\n",
    "\n",
    "logger.info(\"✅ Ambiente carregado e cliente Groq configurado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bf893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NORMALIZAÇÃO DE QUERIES\n",
    "# ============================================================\n",
    "\n",
    "def normalize_query(q):\n",
    "    \"\"\"Remove espaços invisíveis + normaliza Unicode + limpa whitespace.\"\"\"\n",
    "    if pd.isna(q):\n",
    "        return \"\"\n",
    "    q = str(q)\n",
    "\n",
    "    q = unicodedata.normalize(\"NFKC\", q)    # normalização Unicode\n",
    "    q = q.replace(\"\\u200b\", \"\")             # zero-width space\n",
    "    q = q.replace(\"\\xa0\", \" \")              # NBSP\n",
    "    q = \" \".join(q.split())                 # remover múltiplos espaços / trim\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b22a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 10:19:56 | INFO | Total de linhas: 550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Value</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antihistaminique</td>\n",
       "      <td>100</td>\n",
       "      <td>Top</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Antihistamine</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antihistaminiques</td>\n",
       "      <td>27</td>\n",
       "      <td>Top</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Antihistamine</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مضادات الهيستامين</td>\n",
       "      <td>21</td>\n",
       "      <td>Top</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Antihistamine</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>les antihistaminiques</td>\n",
       "      <td>12</td>\n",
       "      <td>Top</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Antihistamine</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anti histaminique</td>\n",
       "      <td>12</td>\n",
       "      <td>Top</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Antihistamine</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Query Value Type  Country          Topic  Year\n",
       "0       antihistaminique   100  Top  Algeria  Antihistamine  2024\n",
       "1      antihistaminiques    27  Top  Algeria  Antihistamine  2024\n",
       "2      مضادات الهيستامين    21  Top  Algeria  Antihistamine  2024\n",
       "3  les antihistaminiques    12  Top  Algeria  Antihistamine  2024\n",
       "4      anti histaminique    12  Top  Algeria  Antihistamine  2024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. LER FICHEIRO EXCEL\n",
    "# ============================================================\n",
    "\n",
    "def load_queries(path=\"TEST_queries_middle_east.xlsx\"):\n",
    "    df = pd.read_excel(path)\n",
    "    # df = df.tail(5)  # PARA TESTES RÁPIDOS — descomentar se quiseres\n",
    "\n",
    "    if \"Query\" not in df.columns:\n",
    "        raise ValueError(\"A coluna 'Query' não existe no ficheiro.\")\n",
    "\n",
    "    # Remover linhas com queries vazias\n",
    "    df = df.dropna(subset=[\"Query\"]).copy()\n",
    "\n",
    "    # print('Antes')\n",
    "    # print(df[\"Query\"])\n",
    "    # print('---')\n",
    "    # Normalização das queries\n",
    "    df[\"Query\"] = df[\"Query\"].apply(normalize_query)\n",
    "    # print('Depois')\n",
    "    # print(df[\"Query\"])\n",
    "\n",
    "    # df[\"QueryID\"] = range(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "# TESTE: carregar e espreitar\n",
    "df = load_queries()\n",
    "logger.info(f\"Total de linhas: {len(df)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a84ef3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 10:20:04 | INFO | Queries únicas: 293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antihistaminique</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antihistaminiques</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مضادات الهيستامين</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>les antihistaminiques</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anti histaminique</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Query  UniqueID\n",
       "0       antihistaminique         1\n",
       "1      antihistaminiques         2\n",
       "2      مضادات الهيستامين         3\n",
       "3  les antihistaminiques         4\n",
       "4      anti histaminique         5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. REMOVER DUPLICADOS POR TEXTO\n",
    "# ============================================================\n",
    "\n",
    "def deduplicate_queries(df):\n",
    "    df_unique = df[[\"Query\"]].drop_duplicates().reset_index(drop=True)\n",
    "    df_unique[\"UniqueID\"] = range(1, len(df_unique) + 1)\n",
    "    return df_unique\n",
    "\n",
    "df_unique = deduplicate_queries(df)\n",
    "logger.info(f\"Queries únicas: {len(df_unique)}\")\n",
    "df_unique.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038f76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. BATCHING\n",
    "# ============================================================\n",
    "\n",
    "def chunk_list(df_or_list, n):\n",
    "    \"\"\"\n",
    "    Se receber DataFrame, faz slicing por linhas.\n",
    "    Se receber lista, faz slicing normal.\n",
    "    \"\"\"\n",
    "    if isinstance(df_or_list, pd.DataFrame):\n",
    "        for i in range(0, len(df_or_list), n):\n",
    "            yield df_or_list.iloc[i:i+n]\n",
    "    else:\n",
    "        for i in range(0, len(df_or_list), n):\n",
    "            yield df_or_list[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5dc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. PROMPT — SUPPLEMENT BOX 2A (COM JSON)\n",
    "# ============================================================\n",
    "\n",
    "def build_prompt_for_batch(batch):\n",
    "    text = (\n",
    "        \"We have extracted several queries from GoogleTrends from the following \"\n",
    "        \"nine countries: Algeria, Egypt, Iran, Iraq, Morocco, Pakistan, Saudi Arabia, \"\n",
    "        \"Turkey and the United Arab Emirates.\\n\\n\"\n",
    "        \"We want to identify which queries explicitly convey a question. \"\n",
    "        \"These queries can be in English, Portuguese, French, Spanish or in any language \"\n",
    "        \"spoken in the aforementioned countries.\\n\\n\"\n",
    "        \"Below, you can find the list of queries.\\n\\n\"\n",
    "        \"For each query, return a JSON array where each element has the form:\\n\"\n",
    "        \"{ \\\"query\\\": \\\"<query text>\\\", \\\"explicit_question\\\": \\\"YES\\\" or \\\"NO\\\" }\\n\\n\"\n",
    "        \"Write \\\"YES\\\" only if the query explicitly conveys a question. \"\n",
    "        \"Otherwise, write \\\"NO\\\".\\n\\n\"\n",
    "        \"List of queries to be classified:\\n\"\n",
    "    )\n",
    "\n",
    "    for q in batch:\n",
    "        text += f\"- {q}\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# ============================================================\n",
    "# 5. FUNÇÃO PARA EXTRAIR JSON DA RESPOSTA DO LLM\n",
    "# ============================================================\n",
    "\n",
    "def safe_json_extract(text):\n",
    "    \"\"\"\n",
    "    Extrai JSON mesmo que exista texto antes/depois do array.\n",
    "    Encontra o bloco entre '[' e ']' e tenta json.loads().\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    candidate = match.group(0).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b789a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have extracted several queries from GoogleTrends from the following nine countries: Algeria, Egypt, Iran, Iraq, Morocco, Pakistan, Saudi Arabia, Turkey and the United Arab Emirates.\n",
      "\n",
      "We want to identify which queries explicitly convey a question. These queries can be in English, Portuguese, French, Spanish or in any language spoken in the aforementioned countries.\n",
      "\n",
      "Below, you can find the list of queries.\n",
      "\n",
      "For each query, return a JSON array where each element has the form:\n",
      "{ \"query\": \"<query text>\", \"explicit_question\": \"YES\" or \"NO\" }\n",
      "\n",
      "Write \"YES\" only if the query explicitly conveys a question. Otherwise, write \"NO\".\n",
      "\n",
      "List of queries to be classified:\n",
      "- antihistaminique\n",
      "- antihistaminiques\n",
      "- مضادات الهيستامين\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_prompt = build_prompt_for_batch(df_unique[\"Query\"].head(3).tolist())\n",
    "print(test_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ca6591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'antihistaminique', 'explicit_question': 'NO'},\n",
       " {'query': 'antihistaminiques', 'explicit_question': 'NO'},\n",
       " {'query': 'مضادات الهيستامين', 'explicit_question': 'NO'},\n",
       " {'query': 'les antihistaminiques', 'explicit_question': 'NO'},\n",
       " {'query': 'anti histaminique', 'explicit_question': 'NO'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. FUNÇÃO PARA CLASSIFICAR UM BATCH COM O LLM\n",
    "# ============================================================\n",
    "\n",
    "def classify_batch_with_llm(batch):\n",
    "    \"\"\"\n",
    "    Devolve lista de dicts: { \"query\": ..., \"explicit_question\": \"YES\"/\"NO\" }\n",
    "    \"\"\"\n",
    "    prompt = build_prompt_for_batch(batch)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content\n",
    "\n",
    "    # print(raw)  # para debug\n",
    "\n",
    "    data = safe_json_extract(raw)\n",
    "\n",
    "    if data is None:\n",
    "        logger.warning(f\"Falha ao extrair JSON. Resposta bruta: {raw}\")\n",
    "        return []\n",
    "\n",
    "    cleaned = []\n",
    "    for item in data:\n",
    "        cleaned.append({\n",
    "            \"query\": item.get(\"query\", \"\").strip(),\n",
    "            \"explicit_question\": item.get(\"explicit_question\", \"NO\").strip().upper()\n",
    "        })\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "# TESTE COM UM MINI-BATCH\n",
    "mini_batch = df_unique[\"Query\"].head(5).tolist()\n",
    "test_output = classify_batch_with_llm(mini_batch)\n",
    "test_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6cacfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 10:20:49 | INFO | LLM_run1 - batch com 20 queries...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>LLM_run1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID LLM_run1\n",
       "0         1       NO\n",
       "1         2       NO\n",
       "2         3       NO\n",
       "3         4       NO\n",
       "4         5       NO"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. FUNÇÃO: EXECUTAR UMA RUN COMPLETA (RUN 1 / RUN 2)\n",
    "# ============================================================\n",
    "\n",
    "def run_llm_classification(df_unique, run_name):\n",
    "    rows = df_unique[[\"UniqueID\", \"Query\"]]\n",
    "    results = []\n",
    "\n",
    "    for batch_df in chunk_list(rows, BATCH_SIZE):\n",
    "        logger.info(f\"{run_name} - batch com {len(batch_df)} queries...\")\n",
    "\n",
    "        batch_queries = batch_df[\"Query\"].tolist()\n",
    "        batch_ids = batch_df[\"UniqueID\"].tolist()\n",
    "\n",
    "        out = classify_batch_with_llm(batch_queries)\n",
    "\n",
    "        for uid, item in zip(batch_ids, out):\n",
    "            results.append({\n",
    "                \"UniqueID\": uid,\n",
    "                run_name: item[\"explicit_question\"]\n",
    "            })\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ⚠️ Para testes usa um subset:\n",
    "df_unique_test = df_unique.head(20).copy()\n",
    "df_run1_test = run_llm_classification(df_unique_test, \"LLM_run1\")\n",
    "df_run1_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f39381f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>Rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antihistaminique</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antihistaminiques</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مضادات الهيستامين</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>les antihistaminiques</td>\n",
       "      <td>4</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anti histaminique</td>\n",
       "      <td>5</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Query  UniqueID Rules\n",
       "0       antihistaminique         1    NO\n",
       "1      antihistaminiques         2    NO\n",
       "2      مضادات الهيستامين         3    NO\n",
       "3  les antihistaminiques         4    NO\n",
       "4      anti histaminique         5    NO"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8. CLASSIFICAÇÃO POR REGRAS MULTILINGUE\n",
    "# ============================================================\n",
    "\n",
    "QUESTION_WORDS = {\n",
    "    \"en\": [\"what\",\"why\",\"how\",\"when\",\"where\",\"which\",\"who\",\"whom\",\"whose\",\n",
    "           \"is\",\"are\",\"am\",\"do\",\"does\",\"did\",\"can\",\"could\",\"should\",\"would\",\n",
    "           \"may\",\"might\",\"will\",\"shall\",\"have\",\"has\",\"had\"],\n",
    "    \"es\": [\"qué\",\"que\",\"cómo\",\"cuando\",\"dónde\",\"cual\",\"cuál\",\"quién\",\"quien\",\n",
    "           \"por qué\",\"porque?\",\"puedo\",\"puede\",\"pueden\",\"debo\",\"debe\",\"deben\"],\n",
    "    \"pt\": [\"o que\",\"que\",\"porquê\",\"porque?\",\"como\",\"quando\",\"onde\",\"qual\",\n",
    "           \"quais\",\"quem\",\"pode\",\"podemos\",\"devo\",\"deves\",\"devemos\"],\n",
    "    \"fr\": [\"quoi\",\"pourquoi\",\"comment\",\"quand\",\"où\",\"quel\",\"quelle\",\"quels\",\n",
    "           \"que\",\"qui\",\"est-ce que\",\"peux-tu\",\"pouvez-vous\"],\n",
    "    \"ar\": [\"ما\",\"ماذا\",\"كيف\",\"لماذا\",\"متى\",\"أين\",\"هل\",\"كم\"],\n",
    "    \"fa\": [\"چی\",\"چه\",\"چرا\",\"چطور\",\"کجا\",\"کی\",\"آیا\"],\n",
    "    \"tr\": [\"ne\",\"neden\",\"nasıl\",\"ne zaman\",\"nerede\",\"hangi\",\"kim\",\"mı\",\"mi\",\"mu\",\"mü\"],\n",
    "    \"ur\": [\"کیا\",\"کیوں\",\"کیسے\",\"کب\",\"کہاں\",\"کون\",\"آیا\"]\n",
    "}\n",
    "\n",
    "ALL_QUESTION_WORDS = list({kw for kws in QUESTION_WORDS.values() for kw in kws})\n",
    "\n",
    "PATTERNS = [\n",
    "    r\".*\\? *$\",\n",
    "    r\"^(\\s*)(is|are|am|do|does|did|can|could|should|would|have|has|had)\\b\",\n",
    "    r\"^(\\s*)est-ce que\\b\",\n",
    "    r\"\\b(mı|mi|mu|mü)\\?$\",\n",
    "    r\"^(.*?)\\b(há|há alguma|será que)\\b\",\n",
    "    r\"^(.*?)\\b(acaso|será que)\\b\",\n",
    "    r\"^(\\s*)آیا\\b\",\n",
    "    r\"^(\\s*)هل\\b\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_question_multilingual(text):\n",
    "    text = (text or \"\").strip().lower()\n",
    "\n",
    "    if text.endswith(\"?\"):\n",
    "        return True\n",
    "\n",
    "    for kw in ALL_QUESTION_WORDS:\n",
    "        if re.search(r\"\\b\" + re.escape(kw) + r\"\\b\", text):\n",
    "            return True\n",
    "\n",
    "    for pattern in PATTERNS:\n",
    "        if re.search(pattern, text):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def apply_multilingual_rules(df_unique):\n",
    "    df_unique[\"Rules\"] = df_unique[\"Query\"].apply(\n",
    "        lambda x: \"YES\" if is_question_multilingual(x) else \"NO\"\n",
    "    )\n",
    "    return df_unique\n",
    "\n",
    "# TESTE\n",
    "df_unique_test = apply_multilingual_rules(df_unique.head(20).copy())\n",
    "df_unique_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3960ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 11:07:13 | INFO | LLM_run1 - batch com 50 queries...\n",
      "2025-12-03 11:07:16 | INFO | LLM_run1 - batch com 50 queries...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbfd6k7hf9fbsch4kf9n01ag` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99882, Requested 552. Please try again in 6m14.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 30\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_final\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Exemplo de pipeline completo em modo “manual”:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# start_time = time.time()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Para testes, subset:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# df_unique_small = df_unique.tail(20).copy()\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m df_run1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_llm_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_unique\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLLM_run1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m df_run1\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_run1_test.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# df_run2 = run_llm_classification(df_unique, \"LLM_run2\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# df_run2.to_excel(\"df_run2_test.xlsx\", index=False)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# df_unique = apply_multilingual_rules(df_unique)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# elapsed = int(time.time() - start_time)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# logger.info(f\"Tempo total (subset): {elapsed} segundos\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m, in \u001b[0;36mrun_llm_classification\u001b[0;34m(df_unique, run_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_queries \u001b[38;5;241m=\u001b[39m batch_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     13\u001b[0m batch_ids \u001b[38;5;241m=\u001b[39m batch_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniqueID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 15\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_batch_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_queries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_ids, out):\n\u001b[1;32m     18\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniqueID\u001b[39m\u001b[38;5;124m\"\u001b[39m: uid,\n\u001b[1;32m     20\u001b[0m         run_name: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicit_question\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mclassify_batch_with_llm\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mDevolve lista de dicts: { \"query\": ..., \"explicit_question\": \"YES\"/\"NO\" }\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m prompt \u001b[38;5;241m=\u001b[39m build_prompt_for_batch(batch)\n\u001b[0;32m---> 11\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m raw \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(raw)  # para debug\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/decide_env/lib/python3.10/site-packages/groq/resources/chat/completions.py:461\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m    301\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitation_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompound_custom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisable_tool_validation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/decide_env/lib/python3.10/site-packages/groq/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/decide_env/lib/python3.10/site-packages/groq/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1043\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbfd6k7hf9fbsch4kf9n01ag` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99882, Requested 552. Please try again in 6m14.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9. MERGE FINAL\n",
    "# ============================================================\n",
    "\n",
    "def merge_results(df_original, df_unique, df_run1, df_run2):\n",
    "    temp = df_unique.merge(df_run1, on=\"UniqueID\", how=\"left\")\n",
    "    temp = temp.merge(df_run2, on=\"UniqueID\", how=\"left\")\n",
    "\n",
    "    df_final = df_original.merge(\n",
    "        temp[[\"Query\", \"Rules\", \"LLM_run1\", \"LLM_run2\"]],\n",
    "        on=\"Query\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Exemplo de pipeline completo em modo “manual”:\n",
    "\n",
    "start_time = time.time()\n",
    "logger.info(\"=== PIPELINE COMPLETO (TESTE EM SUBSET) ===\")\n",
    "\n",
    "df = load_queries()\n",
    "df_unique = deduplicate_queries(df)\n",
    "\n",
    "df_unique.to_excel(\"unique_test.xlsx\", index=False)\n",
    "\n",
    "# Para testes, subset:\n",
    "df_unique_small = df_unique.tail(20).copy()\n",
    "\n",
    "df_run1 = run_llm_classification(df_unique, \"LLM_run1\")\n",
    "df_run1.to_excel(\"df_run1_test.xlsx\", index=False)\n",
    "\n",
    "df_unique_shuffled = df_unique.sample(frac=1, random_state=None).reset_index(drop=True)  # sample() função pandas usada para escolher linhas de forma aleatória\n",
    "df_run2 = run_llm_classification(df_unique_shuffled, \"LLM_run2\")\n",
    "# df_run2 = run_llm_classification(df_unique, \"LLM_run2\")\n",
    "df_run2.to_excel(\"df_run2_test.xlsx\", index=False)\n",
    "df_unique = apply_multilingual_rules(df_unique)\n",
    "df_unique.to_excel(\"df_unique_small_test.xlsx\", index=False)\n",
    "\n",
    "df_final_test = merge_results(df, df_unique, df_run1, df_run2)\n",
    "df_final_test.to_excel(\"df_final_test.xlsx\", index=False)\n",
    "df_final_test.head()\n",
    "\n",
    "elapsed = int(time.time() - start_time)\n",
    "logger.info(f\"Tempo total (subset): {elapsed} segundos\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decide_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
